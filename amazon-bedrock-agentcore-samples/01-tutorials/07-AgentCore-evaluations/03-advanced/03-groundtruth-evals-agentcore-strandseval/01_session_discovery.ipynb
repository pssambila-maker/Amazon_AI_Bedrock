{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Discovery\n",
    "\n",
    "This notebook discovers agent sessions from AgentCore Observability for offline evaluation. It queries your agent's trace log group to find sessions, then saves them to a JSON file for processing in the analysis notebook.\n",
    "\n",
    "**Two Discovery Methods:**\n",
    "\n",
    "1. **Time-based**: Find all sessions within a time window. Use this for bulk evaluation of recent agent activity.\n",
    "\n",
    "2. **Score-based**: Find sessions by existing evaluation score from AgentCore. Use this to re-evaluate low-scoring sessions with updated rubrics.\n",
    "\n",
    "**Output:** `discovered_sessions.json` containing session IDs and metadata for the analysis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Where This Fits\n\nThis is **Notebook 1** in the evaluation workflow. After discovering sessions here, you'll choose one of two evaluation paths.\n\n![Notebook Workflow](images/notebook_workflow.svg)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules and load configuration from `config.py`. All configuration values can be overridden via environment variables before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "from config import (\n",
    "    AWS_REGION,\n",
    "    SOURCE_LOG_GROUP,\n",
    "    EVAL_RESULTS_LOG_GROUP_FULL,\n",
    "    LOOKBACK_HOURS,\n",
    "    MAX_SESSIONS,\n",
    "    MIN_SCORE,\n",
    "    MAX_SCORE,\n",
    "    DISCOVERED_SESSIONS_PATH,\n",
    "    EVALUATOR_NAME,\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    ObservabilityClient,\n",
    "    SessionDiscoveryResult,\n",
    "    # SessionInfo,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The `EVALUATOR_NAME` used for score-based discovery is loaded from `config.py`. This must match the evaluator name in your existing evaluation results. Modify `config.py` to change settings like `LOOKBACK_HOURS`, `MAX_SESSIONS`, or score thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATOR_NAME is loaded from config.py\n",
    "print(f\"Using evaluator: {EVALUATOR_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "\n",
    "Create the `ObservabilityClient` which handles CloudWatch Logs Insights queries. The time range is calculated from `LOOKBACK_HOURS` in config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_client = ObservabilityClient(\n",
    "    region_name=AWS_REGION,\n",
    "    log_group=SOURCE_LOG_GROUP,\n",
    ")\n",
    "\n",
    "end_time = datetime.now(timezone.utc)\n",
    "start_time = end_time - timedelta(hours=LOOKBACK_HOURS)\n",
    "start_time_ms = int(start_time.timestamp() * 1000)\n",
    "end_time_ms = int(end_time.timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Based Discovery\n",
    "\n",
    "Query the AgentCore Observability log group for all unique session IDs within the time window. Returns sessions with span counts and timestamps, sorted by most recent activity. Use this method when you want to evaluate all recent agent interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_based_sessions = obs_client.discover_sessions(\n",
    "    start_time_ms=start_time_ms,\n",
    "    end_time_ms=end_time_ms,\n",
    "    limit=MAX_SESSIONS,\n",
    ")\n",
    "\n",
    "print(f\"Discovered {len(time_based_sessions)} sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score-Based Discovery\n",
    "\n",
    "Query the AgentCore evaluation results log group to find sessions by their existing evaluation scores. Filters sessions where the specified evaluator scored between `MIN_SCORE` and `MAX_SCORE`. Use this method to find poorly-performing sessions for re-evaluation with updated rubrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_based_sessions = obs_client.discover_sessions_by_score(\n",
    "    evaluation_log_group=EVAL_RESULTS_LOG_GROUP_FULL,\n",
    "    evaluator_name=EVALUATOR_NAME,\n",
    "    start_time_ms=start_time_ms,\n",
    "    end_time_ms=end_time_ms,\n",
    "    min_score=MIN_SCORE,\n",
    "    max_score=MAX_SCORE,\n",
    "    limit=MAX_SESSIONS,\n",
    ")\n",
    "\n",
    "print(f\"Discovered {len(score_based_sessions)} sessions by score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Discovery Method\n",
    "\n",
    "Choose which set of discovered sessions to use. Set `USE_TIME_BASED = True` for time-based results, or `False` for score-based results. The selected sessions are packaged into a `SessionDiscoveryResult` with metadata about how they were discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to use score-based discovery instead\n",
    "USE_TIME_BASED = True\n",
    "\n",
    "if USE_TIME_BASED:\n",
    "    selected_sessions = time_based_sessions\n",
    "    discovery_method = \"time_based\"\n",
    "    log_group = SOURCE_LOG_GROUP\n",
    "    filter_criteria = None\n",
    "else:\n",
    "    selected_sessions = score_based_sessions\n",
    "    discovery_method = \"score_based\"\n",
    "    log_group = EVAL_RESULTS_LOG_GROUP_FULL\n",
    "    filter_criteria = {\n",
    "        \"evaluator_name\": EVALUATOR_NAME,\n",
    "        \"min_score\": MIN_SCORE,\n",
    "        \"max_score\": MAX_SCORE,\n",
    "    }\n",
    "\n",
    "discovery_result = SessionDiscoveryResult(\n",
    "    sessions=selected_sessions,\n",
    "    discovery_time=datetime.now(timezone.utc),\n",
    "    log_group=log_group,\n",
    "    time_range_start=start_time,\n",
    "    time_range_end=end_time,\n",
    "    discovery_method=discovery_method,\n",
    "    filter_criteria=filter_criteria,\n",
    ")\n",
    "\n",
    "print(f\"Selected {len(selected_sessions)} sessions via {discovery_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Sessions\n",
    "\n",
    "View the first 10 discovered sessions. For time-based discovery, this shows session ID and span count. For score-based discovery, this shows session ID and average evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, session in enumerate(selected_sessions[:10]):\n",
    "    meta = session.metadata or {}\n",
    "    if discovery_method == \"time_based\":\n",
    "        print(f\"{i+1}. {session.session_id} - {session.span_count} spans\")\n",
    "    else:\n",
    "        print(f\"{i+1}. {session.session_id} - avg_score: {meta.get('avg_score', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "Save the discovery result to JSON. This file will be loaded by the analysis notebook to process each session. The output path is configured in `config.py` as `DISCOVERED_SESSIONS_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discovery_result.save_to_json(DISCOVERED_SESSIONS_PATH)\n",
    "print(f\"Saved {len(selected_sessions)} sessions to {DISCOVERED_SESSIONS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Output\n",
    "\n",
    "Confirm the JSON file was saved correctly. After verification, proceed to the multi-session analysis notebook to evaluate these sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(DISCOVERED_SESSIONS_PATH, \"r\") as f:\n",
    "    saved_data = json.load(f)\n",
    "\n",
    "print(f\"Sessions: {len(saved_data['sessions'])}\")\n",
    "print(f\"Method: {saved_data['discovery_method']}\")\n",
    "print(f\"Time range: {saved_data['time_range_start']} to {saved_data['time_range_end']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}