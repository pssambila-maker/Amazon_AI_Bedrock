{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Prerequisites & Infrastructure Setup\n",
    "\n",
    "## Overview\n",
    "Verify all prerequisites for the workshop and deploy the CRM application stack on AWS (EC2 + NGINX + DynamoDB).\n",
    "\n",
    "## Objectives\n",
    "**Part 1: Prerequisites**\n",
    "- Verify Python version (3.10+)\n",
    "- Verify AWS account and credentials\n",
    "- Install workshop dependencies\n",
    "- Verify Bedrock AgentCore SDK and starter toolkit\n",
    "- Test Bedrock model access\n",
    "- Set up Agent Memory for shared context\n",
    "- Set up User and Agent identities using Amazon Cognito\n",
    "\n",
    "**Part 2: Infrastructure Setup**\n",
    "- Provision AWS infrastructure: EC2 instance, NGINX, DynamoDB, CloudWatch\n",
    "- Deploy a sample CRM application\n",
    "- Create fault injection scripts to simulate failures\n",
    "- Set up CloudWatch monitoring\n",
    "- Verify infrastructure is running and accessible\n",
    "\n",
    "## What You'll Learn\n",
    "- Workshop prerequisites and setup workflow\n",
    "- Fault injection patterns for testing incident response\n",
    "- CloudWatch log and metric setup for diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verify Python Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "assert sys.version_info >= (3, 10), \"Python 3.10+ required\"\n",
    "print(\"✅ Python version check passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Workshop Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt\n",
    "print(\"✅ Workshop dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify AWS Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from lab_helpers.config import AWS_REGION, AWS_PROFILE, MODEL_ID, WORKSHOP_NAME\n",
    "from lab_helpers.lab_01.infrastructure import get_app_url\n",
    "\n",
    "# Display configuration\n",
    "print(f\"Workshop Name: {WORKSHOP_NAME}\")\n",
    "print(f\"AWS Region: {AWS_REGION}\")\n",
    "print(f\"Model ID: {MODEL_ID}\\n\")\n",
    "\n",
    "# Verify AWS credentials\n",
    "session = boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION)\n",
    "sts = session.client('sts')\n",
    "identity = sts.get_caller_identity()\n",
    "\n",
    "print(f\"✅ AWS Account: {identity['Account']}\")\n",
    "print(f\"✅ AWS User/Role: {identity['Arn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Bedrock Model Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from lab_helpers.config import AWS_REGION, MODEL_ID, AWS_PROFILE\n",
    "\n",
    "session = boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION)\n",
    "bedrock = session.client('bedrock', region_name=AWS_REGION)\n",
    "\n",
    "# Verify model access\n",
    "try:\n",
    "    model = bedrock.get_foundation_model(modelIdentifier=MODEL_ID)\n",
    "    print(f\"Model ID: {MODEL_ID}\")\n",
    "    print(f\"✅ Bedrock model access verified\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error accessing model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify AgentCore Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "packages = ['bedrock_agentcore', 'strands', 'boto3', 'pydantic']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        mod = importlib.import_module(package)\n",
    "        version = getattr(mod, '__version__', 'installed')\n",
    "        print(f\"✅ {package:<20} {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {package:<20} NOT FOUND\")\n",
    "\n",
    "print(\"\\n✅ All core packages verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "✅ All prerequisites verified. Ready to proceed to Lab 1: Infrastructure Setup & Fault Injection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5: Cognito Setup (Authentication for Labs 3-5)\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this section, we'll set up AWS Cognito for authentication infrastructure used by Labs 3-5:\n",
    "\n",
    "**What We'll Create:**\n",
    "- Cognito User Pool: `aiml301-UserPool`\n",
    "- **Two User Groups** (NEW):\n",
    "  - **developers**: Users who create remediation plans\n",
    "  - **approvers**: Users who approve and execute plans\n",
    "- **Two App Clients**:\n",
    "  - **User Auth Client** (public): For end-user authentication with OAuth support\n",
    "  - **M2M Client** (confidential): For Gateway-to-Runtime service-to-service authentication\n",
    "- **Resource Server**: Custom scopes for fine-grained authorization (`mcp.invoke`, `runtime.access`)\n",
    "- **User Pool Domain**: OAuth2 token endpoint\n",
    "- **Two Test Users**:\n",
    "  - **Developer User**: `testuser@aiml301.example.com` (member of `developers` group)\n",
    "  - **Approver User**: `approver@aiml301.example.com` (member of `approvers` group)\n",
    "\n",
    "**Authentication Flows:**\n",
    "1. **User Auth** (Client → Gateway): End-users authenticate with credentials, receive JWT tokens with group membership\n",
    "2. **M2M Auth** (Gateway → Runtime): Gateway uses client credentials grant to get M2M tokens for Runtime access\n",
    "\n",
    "**Multi-Actor Workflow (Lab-03):**\n",
    "- **Developer** logs in → Creates remediation plan → Gets blocked (needs approval)\n",
    "- **Approver** logs in → Discovers pending incidents → Reviews plan → Approves execution\n",
    "- **Developer** returns → Sees approval in shared memory → Executes approved steps\n",
    "\n",
    "**JWT Token Claims:**\n",
    "After setup, JWT ID tokens will include:\n",
    "```json\n",
    "{\n",
    "  \"email\": \"developer@aiml301.example.com\",\n",
    "  \"cognito:username\": \"developer@aiml301.example.com\",\n",
    "  \"cognito:groups\": [\"developers\"],\n",
    "  \"sub\": \"uuid\",\n",
    "  \"scope\": \"openid profile email custom-scopes\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Why Groups?**\n",
    "- **Role-based authorization**: Gateway can check if user is in `approvers` group before allowing execution\n",
    "- **Incident routing**: Only notify approvers for pending incidents\n",
    "- **Audit trails**: Memory records show which role performed each action\n",
    "- **Actor identification**: `email` claim provides readable actor_id instead of UUID\n",
    "\n",
    "### Objectives\n",
    "\n",
    "✅ Set up Cognito infrastructure for centralized authentication\n",
    "✅ Create user groups for role-based access control\n",
    "✅ Enable dual auth modes: user-based and service-to-service\n",
    "✅ Create fine-grained authorization scopes\n",
    "✅ Enable OAuth flows for rich JWT ID tokens\n",
    "✅ Store configuration in SSM Parameter Store for use by later labs\n",
    "\n",
    "#### 1. Execute Cognito Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lab_helpers.cognito_setup import setup_cognito_complete\n",
    "\n",
    "# Execute complete Cognito setup workflow\n",
    "cognito_config = setup_cognito_complete()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COGNITO SETUP COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Cognito User Pool ID: \", cognito_config['user_pool_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.6: Memory Setup for Labs 2-5\n",
    "\n",
    "In this section, we'll create a shared AgentCore Memory resource that will be used by all agent labs (2-5) for conversation history and session management.\n",
    "\n",
    "### What We'll Create:\n",
    "- AgentCore Memory resource with 7-day expiry\n",
    "- Store memory_id in Parameter Store for easy access by Labs 2-5\n",
    "- Store default session ID for static session tracking in Labs 2-4\n",
    "\n",
    "### Key Learning:\n",
    "Memory enables context persistence across agent calls and multi-turn conversations. All labs will share this single memory resource.\n",
    "\n",
    "### Objectives\n",
    "✅ Create AgentCore Memory resource  \n",
    "✅ Store memory configuration in Parameter Store  \n",
    "✅ Enable conversation history loading for downstream agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.6.1: Create AgentCore Memory Resource\n",
    "\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from lab_helpers.constants import PARAMETER_PATHS\n",
    "from datetime import datetime\n",
    "\n",
    "memory_client = MemoryClient(region_name=AWS_REGION)\n",
    "memory_name = f\"{PARAMETER_PATHS['memory']['memory_name_prefix']}_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "print(f\"Creating memory: {memory_name}\")\n",
    "memory = memory_client.create_memory_and_wait(\n",
    "    name=memory_name,\n",
    "    description=\"SRE Agent Shared Short-Term Memory for Labs 2-5\",\n",
    "    strategies=[],\n",
    "    event_expiry_days=7,\n",
    "    max_wait=600,\n",
    "    poll_interval=10\n",
    ")\n",
    "\n",
    "memory_id = memory['id']\n",
    "print(f\"✅ Memory created: {memory_id} (Status: ACTIVE, Expiry: 7 days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.6.2: Store Memory Configuration in Parameter Store\n",
    "\n",
    "from lab_helpers.parameter_store import put_parameter\n",
    "\n",
    "# Store memory_id for Labs 2-5\n",
    "put_parameter(\n",
    "    PARAMETER_PATHS['memory']['memory_id'],\n",
    "    memory_id,\n",
    "    description=\"Memory ID for agent conversation history\",\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "# Store default session ID for Labs 2-4\n",
    "put_parameter(\n",
    "    PARAMETER_PATHS['memory']['default_session_id'],\n",
    "    \"crm-session-id\",\n",
    "    description=\"Default session ID for Labs 2-4\",\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "print(f\"✅ PSM Keys stored:\")\n",
    "print(f\"   • {PARAMETER_PATHS['memory']['memory_id']} = {memory_id}\")\n",
    "print(f\"   • {PARAMETER_PATHS['memory']['default_session_id']} = crm-session-id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: Memory Setup Complete\n",
    "\n",
    "✅ **AgentCore Memory Resource Created**\n",
    "- Single shared memory resource for all labs (2-5)\n",
    "- Automatic 7-day expiry for cost management\n",
    "- Supports multi-turn conversations and context loading\n",
    "\n",
    "✅ **Parameter Store Configuration**\n",
    "- Memory ID stored for Lab 2-5 retrieval\n",
    "- Default session ID available for Labs 2-4\n",
    "- Follows central configuration pattern\n",
    "\n",
    "**Next Steps:**\n",
    "- Lab 2: Retrieve memory_id and initialize memory hooks\n",
    "- Lab 3-4: Use same memory for remediation/prevention agents\n",
    "- Lab 5: Multi-agent orchestration with shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Infrastructure Setup & CRM Application Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Infrastructure Setup & CRM Application Deployment is automated is a part of the workshop set up.\n",
    "\n",
    "Please proceed to the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try url with both port 80 and 8080\n",
    "print(f\"Click here to access the CRM App UI: '{get_app_url()}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Up Fault Injection Utilities\n",
    "\n",
    "In this section, we'll prepare tools to inject infrastructure faults and review pre-baked faults already built into the deployment. The workshop includes **4 total faults** for comprehensive SRE training:\n",
    "\n",
    "- **Fault 1: DynamoDB Throttling** - Reduce table capacity to trigger ProvisionedThroughputExceededException\n",
    "- **Fault 2: IAM Permission Issues** - Restrict EC2 role permissions to cause AccessDenied errors\n",
    "\n",
    "These faults will be used throughout the workshop to test your SRE agent's diagnostic capabilities across different failure modes and detection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab_helpers.lab_01.fault_injection import (\n",
    "    initialize_fault_injection,\n",
    "    inject_dynamodb_throttling,\n",
    "    inject_iam_permissions,\n",
    ")\n",
    "\n",
    "# Initialize AWS clients and retrieve infrastructure resource IDs from SSM\n",
    "print(\"Initializing fault injection utilities...\")\n",
    "resources = initialize_fault_injection(AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "print(f\"\\nDiscovered Infrastructure Resources:\")\n",
    "print(f\"  Nginx Instance: {resources.get('nginx_instance_id', 'Not found')}\")\n",
    "print(f\"  App Instance: {resources.get('app_instance_id', 'Not found')}\")\n",
    "print(f\"  CRM Activities Table: {resources.get('crm_activities_table_name', 'Not found')}\")\n",
    "print(f\"  CRM Customers Table: {resources.get('crm_customers_table_name', 'Not found')}\")\n",
    "print(f\"  CRM Deals Table: {resources.get('crm_deals_table_name', 'Not found')}\")\n",
    "print(f\"  EC2 Role: {resources.get('ec2_role_name', 'Not found')}\")\n",
    "print(f\"  Public ALB DNS: {resources.get('public_alb_dns', 'Not found')}\")\n",
    "\n",
    "print(\"\\n✅ Fault injection utilities ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Infrastructure\n",
    "\n",
    "Before injecting faults, let's verify that the CloudFormation stack has created all necessary resources and they are healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab_helpers.lab_01.infrastructure import (\n",
    "    verify_ec2_instances,\n",
    "    verify_dynamodb_tables,\n",
    "    verify_alb_health,\n",
    "    verify_cloudwatch_logs\n",
    ")\n",
    "\n",
    "print(\"Verifying infrastructure components...\\n\")\n",
    "\n",
    "# Verify EC2 instances are running\n",
    "ec2_status = verify_ec2_instances(resources, AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "# Verify DynamoDB tables exist and are accessible\n",
    "dynamodb_status = verify_dynamodb_tables(resources, AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "# Verify ALB targets are healthy\n",
    "alb_status = verify_alb_health(resources, AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "# Verify CloudWatch log groups exist\n",
    "logs_status = verify_cloudwatch_logs(AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "if all([ec2_status, dynamodb_status, alb_status, logs_status]):\n",
    "    print(\"\\n✅ All infrastructure components verified and healthy\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Some infrastructure components failed verification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Fault Injection and Review Pre-Baked Faults\n",
    "\n",
    "In this section, we'll inject two infrastructure faults and review two additional faults that are pre-baked into the deployment. Together, these **4 faults** will provide comprehensive training scenarios for your diagnostic agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault 1: DynamoDB Throttling\n",
    "\n",
    "**What it is:**\n",
    "DynamoDB throttling occurs when your application exceeds the provisioned read/write capacity of your tables. This is a common production issue that can happen when:\n",
    "- Traffic spikes unexpectedly exceed provisioned capacity\n",
    "- Tables are misconfigured with insufficient capacity units\n",
    "\n",
    "**How we inject this fault:**\n",
    "The `inject_dynamodb_throttling()` helper function simulates this by:\n",
    "- Converting the metrics table from `PAY_PER_REQUEST` (unlimited) to `PROVISIONED` billing mode\n",
    "- Setting extremely low capacity limits: **1 Read Capacity Unit** and **1 Write Capacity Unit**\n",
    "- This means the table can only handle ~1 read and ~1 write operation per second\n",
    "- Any normal application load will immediately exceed these limits\n",
    "\n",
    "**Expected impact:**\n",
    "- `ProvisionedThroughputExceededException` errors in application logs\n",
    "- Increased latency as requests get throttled and retried\n",
    "- CloudWatch metrics will show throttled requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute DynamoDB throttling fault injection\n",
    "success = inject_dynamodb_throttling(resources, AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "if success:\n",
    "    print(\"✅ DynamoDB throttling fault injected successfully\")\n",
    "    print(\"   → Table converted to PROVISIONED mode with 1 RCU/1 WCU\")\n",
    "    print(\"   → Normal application load will now trigger throttling\")\n",
    "else:\n",
    "    print(\"❌ Failed to inject DynamoDB throttling fault\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Application Tables \n",
    "\n",
    "Now lets load test our endpoint. We are going to send 20 concurrent requests/second for 30 seconds. This load is not very significant, but due to misconfiguration in the table capacity provisioned - our app should should show `ProvisionedThroughputExceededException` errors in [application logs](https://us-west-2.console.aws.amazon.com/cloudwatch/home?region=us-west-2#logsV2:log-groups/log-group/$252Faws$252Fsre-workshop$252Fcrm-application) and CloudWatch metrics will show throttled requests. If you try to access the Customers tab during the load test, you will experience issues with it loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "alb_dns = resources['public_alb_dns']\n",
    "url = f\"http://{alb_dns}:8080/api/customers\"\n",
    "\n",
    "def make_request(i):\n",
    "    try:\n",
    "        requests.get(url, timeout=5)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for second in range(1, 31):\n",
    "    with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "        executor.map(make_request, range(50))\n",
    "\n",
    "    if second % 10 == 0:\n",
    "        print(f\"Progress: {second}/30 seconds\")\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\n✓ Load test complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fault 2: IAM Permission Issues\n",
    "\n",
    "**What it is:**\n",
    "IAM permission issues occur when applications lack necessary permissions to access AWS resources. This is one of the most common production problems, often caused by:\n",
    "- Overly restrictive security policies applied without testing\n",
    "- Role assumptions failing due to trust policy modifications\n",
    "- Security team applying blanket deny policies\n",
    "\n",
    "**How we inject this fault:**\n",
    "Our helper function `inject_iam_permissions()` simulates this by:\n",
    "- Locating the EC2 instance IAM role used by the application servers\n",
    "- Backing up the original DynamoDB access policy\n",
    "- Replacing it with an explicit **Deny** policy for key DynamoDB operations\n",
    "- Targeting: `PutItem`, `GetItem`, `Query`, `Scan`, `UpdateItem`, `DeleteItem`\n",
    "- Since Deny policies override Allow policies, this immediately blocks database access\n",
    "\n",
    "**Expected impact:**\n",
    "- `AccessDenied` exceptions in application logs for any database operations\n",
    "- Complete failure of features that require DynamoDB access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute IAM permission fault injection\n",
    "success = inject_iam_permissions(resources, AWS_REGION, AWS_PROFILE)\n",
    "\n",
    "if success:\n",
    "    print(\"✅ IAM permission fault injected successfully\")\n",
    "    print(f\"   → EC2 role '{resources.get('ec2_role_name', 'Unknown')}' now has Deny policy\")\n",
    "    print(\"   → All DynamoDB operations will return AccessDenied\")\n",
    "else:\n",
    "    print(\"❌ Failed to inject IAM permission fault\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test what response we get when invoking our application now. We should see error 500 due to the backend issues with the API not being able to retrieve data from DynamoDB.\n",
    "**Note**: It may take a minute for IAM permissions to propagate. If you're not seeing 500 errors, please wait and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(180)\n",
    "alb_dns = resources['public_alb_dns']\n",
    "\n",
    "url = f\"http://{alb_dns}:8080/api/deals\"\n",
    "\n",
    "print(f\"\\nGenerating 5 requests to trigger IAM errors...\")\n",
    "print(f\"Target: {url}\\n\")\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        print(f\"Request {i+1} - Status: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request {i+1} - Error: {str(e)}\")\n",
    "\n",
    "    time.sleep(1)  # Small delay to avoid overwhelming\n",
    "\n",
    "print(\"\\n✓ Load complete - waiting 10 seconds for logs to propagate...\")\n",
    "time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ Prerequisites verified and infrastructure deployed. CRM application is running and monitored via CloudWatch. We have injected faults simulating real production issues for our Agent to troubleshoot.\n",
    "\n",
    "Next: Lab 2 - Build the Diagnostics Agent (Lab-02-diagnostics-agent.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try url with both port 80 and 8080\n",
    "print(f\"Click here to access the CRM App UI: '{get_app_url()}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
